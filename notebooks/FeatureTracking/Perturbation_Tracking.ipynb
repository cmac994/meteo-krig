{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TrackPy Perturbation Tracking (Example)\n",
    "\n",
    "This notebook demonstrates the identification and tracking of mesoscale pressure features (i.e. perturbations) \n",
    "\n",
    "1. Import relevant Python libraries and setup cartopy/colortables\n",
    "\n",
    "2. Retrieve radar data and bandpass filtered mesoscale pressure perturabation analyses over a 48-h period.  \n",
    "\n",
    "3. Perform feature tracking of mesoscale pressure perturbations using scikit-image, hagelsag, and trackpy. \n",
    "\n",
    "4. Demonstrate track-following approach by animating feature tracks overlaid atop mesoscale pressure perturbations during two high-impact weather events (back to back derechoes in the Mid-Atlantic Region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### ---- (1) ---- ####\n",
    "#Import Python libraries\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../PyScripts')\n",
    "import xarray as xr\n",
    "import matplotlib\n",
    "import cmasher as cmr\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import funcs\n",
    "import colorcet as cc\n",
    "import cmasher as cmr\n",
    "from datetime import datetime,timedelta\n",
    "from cartopy.feature import NaturalEarthFeature,BORDERS,LAKES,COLORS\n",
    "import cartopy.crs as crs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "from metpy.plots import colortables\n",
    "from scipy import ndimage\n",
    "from scipy import signal\n",
    "from scipy.signal import butter, lfilter\n",
    "import multiprocessing\n",
    "from joblib import Parallel,delayed\n",
    "from hagelslag.processing import Hysteresis,STObject\n",
    "import trackpy as tp\n",
    "from filterpy.kalman import KalmanFilter\n",
    "from scipy.linalg import block_diag\n",
    "from filterpy.common import Q_discrete_white_noise\n",
    "from scipy.ndimage import find_objects, center_of_mass, label\n",
    "\n",
    "#Retrieve perceptually uniform colorbar from colorcet\n",
    "cmapp = cc.cm.rainbow_bgyrm_35_85_c71\n",
    "\n",
    "#Set format for datetime objects\n",
    "fmt = '%Y%m%d_%H%M'\n",
    "\n",
    "# Download/add state and coastline features for cartopy \n",
    "states = NaturalEarthFeature(category=\"cultural\", scale=\"10m\",\n",
    "                             facecolor=\"none\",\n",
    "                             name=\"admin_1_states_provinces_shp\")\n",
    "\n",
    "land_50m = NaturalEarthFeature('physical', 'land', '10m',\n",
    "                                        edgecolor='k',\n",
    "                                        facecolor='none')\n",
    "\n",
    "#Define function to add map data to matplotlib plot\n",
    "def add_map(ax,clr,lw):\n",
    "    ax.add_feature(states)\n",
    "    ax.add_feature(BORDERS)\n",
    "    ax.add_feature(land_50m)\n",
    "    ax.add_feature(states,edgecolor=clr,lw=lw)\n",
    "    ax.add_feature(LAKES, edgecolor=clr)\n",
    "\n",
    "#Define function to add latitude/longitude grid lines to cartopy/matplotlib plot\n",
    "def add_gridlines(ax,xl,yl,clr, fs):\n",
    "    gl = ax.gridlines(crs=crs.PlateCarree(), draw_labels=True,\n",
    "                      linewidth=0.25, color=clr, alpha=1, linestyle='--')\n",
    "\n",
    "    gl.xlabels_bottom = xl\n",
    "    gl.xlabels_top = False\n",
    "    gl.ylabels_left = yl\n",
    "    gl.ylabels_right = False\n",
    "\n",
    "    gl.xformatter = LONGITUDE_FORMATTER\n",
    "    gl.yformatter = LATITUDE_FORMATTER\n",
    "    gl.xlabel_style = {'size': fs, 'color': clr}\n",
    "    gl.ylabel_style = {'size': fs, 'color': clr}\n",
    "    return gl\n",
    "\n",
    "#Get Composite Reflectivity colormap from metpy\n",
    "ctable1 = 'NWSStormClearReflectivity'\n",
    "cmapp = cc.cm.rainbow_bgyrm_35_85_c71\n",
    "norm, cmapp_radar = colortables.get_with_steps(ctable1, 244, 244)\n",
    "\n",
    "#Increase with of notebook to fill screen\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "#Define function to mask pressure analyses over water\n",
    "def mask_grid(arr):\n",
    "    arr = np.ma.masked_where(landsea==0,arr)\n",
    "    return arr\n",
    "\n",
    "#Define function to read and subset a land/sea boolean grid\n",
    "def get_landsea():\n",
    "    ds_land = xr.open_dataset('../../data/Static/landsea.nc')\n",
    "    ds_land = funcs.subset(ds_land,minLat,maxLat,minLng,maxLng)\n",
    "    landsea = ds_land['LANDSEA'].values\n",
    "    landsea = np.pad(landsea, ((0,1),(0,1)), 'edge')\n",
    "    ds_land.close()\n",
    "    return landsea\n",
    "\n",
    "#Kalman smoother to smooth trajectories\n",
    "def kf_smooth(xs, ys):\n",
    "        tracker = KalmanFilter(dim_x=4, dim_z=2)\n",
    "        dt = 1.   # time step 1 second\n",
    "\n",
    "        tracker.F = np.array([[1, dt, 0,  0],\n",
    "                              [0,  1, 0,  0],\n",
    "                              [0,  0, 1, dt],\n",
    "                              [0,  0, 0,  1]])\n",
    "\n",
    "        q = Q_discrete_white_noise(dim=2, dt=dt, var=0.25)\n",
    "        tracker.Q = block_diag(q, q)\n",
    "        tracker.R = np.array([[np.max(abs(np.diff(xs))), 0],\n",
    "                      [0, np.max(abs(np.diff(ys)))]])\n",
    "\n",
    "        tracker.H = np.array([[1, 0, 0,        0],\n",
    "                      [0,        0, 1, 0]])\n",
    "\n",
    "        tracker.x = np.array([[xs[0], 0, ys[0], 0]]).T\n",
    "        tracker.P = np.eye(4)\n",
    "\n",
    "        zs = np.array([xs,ys]).T\n",
    "\n",
    "        # filter data with Kalman filter, than run smoother on it\n",
    "        mu, cov, _, _ = tracker.batch_filter(zs)\n",
    "        # Perform kalman smoothing\n",
    "        M, P, C, _ = tracker.rts_smoother(mu, cov)\n",
    "        return M[:,0],mu[:,2]\n",
    "\n",
    "#Smooth each trajectory using a Kalman smoother, return storm objects and trajectory paths\n",
    "def smooth_trajs(t1,stg):\n",
    "        t2 = t1.copy()\n",
    "        parts = t2['particle'].unique()\n",
    "\n",
    "        tarr = []; stg_new = []\n",
    "        for p,pp in enumerate(parts):\n",
    "                traj = t2[t2['particle'].values==pp] #Extract trajectory from dataframe\n",
    "                gidx = np.argwhere(t2['particle'].values==pp).T[0]\n",
    "                stot = stg[gidx]\n",
    "\n",
    "                traj2 = traj.copy()\n",
    "\n",
    "                #Smooth trajectory with Kalman RTS smoother\n",
    "                xsm,ysm = kf_smooth(traj['lng'].values,traj['lat'].values)\n",
    "\n",
    "                traj2.iloc[:,4] = xsm\n",
    "                traj2.iloc[:,3] = ysm\n",
    "\n",
    "                tarr.append(traj2)\n",
    "                for s in stot:\n",
    "                    stg_new.append(s)\n",
    "\n",
    "        tnew = pd.concat(tarr)\n",
    "        stg_new = np.array(stg_new)\n",
    "        return tnew,stg_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#---- (2) ---- #\n",
    "\n",
    "#Define dates of analysis and observation type\n",
    "day1 = '20180514'\n",
    "day2 = '20180515'\n",
    "otyp = 'altimeter'\n",
    "\n",
    "#Define bounding box\n",
    "minLng = -83.0; maxLng = -70.5; minLat = 38.5; maxLat= 45.0\n",
    "\n",
    "#Get land/sea boolean within bounding box\n",
    "landsea = get_landsea()\n",
    "landsea = landsea[:-1,:]\n",
    "\n",
    "#Retrieve composite reflectivity for each day: 14-15 of May, 2018\n",
    "dsr_all = xr.open_dataset('../../data/Radar/cref_201805.nc')\n",
    "\n",
    "#Convert observation times into list of datetime objects\n",
    "dts = dsr_all['Valid'].values\n",
    "dtlist = [datetime.utcfromtimestamp(d/1e9).strftime(fmt) for d in dts.tolist()]\n",
    "refl = dsr_all['REFL'].values\n",
    "dsr_all.close()\n",
    "\n",
    "#Read bandpass filtered pressure perturbations from NetCDF (created in AltimeterAnalysis.ipynb)\n",
    "dsp = xr.open_dataset('../../data/KF/kfsmart_bpass_altimeter_'+day2+'.nc')\n",
    "dsp = funcs.subset(dsp,minLat,maxLat,minLng,maxLng)\n",
    "X,Y = np.meshgrid(dsp['longitude'].values,dsp['latitude'].values) #Get lat/lng grid\n",
    "vvar_meso = dsp['altimeter_meso'].values #Retrieve pressure perturbation analysis\n",
    "dsp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- (3) ---- #\n",
    "\n",
    "#Requirements for feature identification (minimum perturbation of 0.75 hPa, must have one pixel exceeding 1 hPa, and must exceed an area of 625 km^2)\n",
    "min_intensity = 0.75; max_intensity=1.0001; min_area = 25\n",
    "\n",
    "#Define labeler\n",
    "labeler1 = Hysteresis(min_intensity, max_intensity)\n",
    "\n",
    "#Define function to label perturbations on grid\n",
    "def label_2d(d,data2d):\n",
    "        #Retrieve labels using scipy ndimage\n",
    "        label_grid2d, num_labels = label(data2d > min_intensity)\n",
    "        #mask regions below intensity threshold\n",
    "        label_grid2d[data2d < min_intensity] = 0\n",
    "        gn = []\n",
    "        #Loop through each label and unlabel regions if perturbation region does not contain a maximum above 1.0 hPa\n",
    "        for n in np.arange(1,num_labels):\n",
    "                gidx = np.argwhere(label_grid2d==n).T\n",
    "                gmax = np.nanmax(abs(data2d[gidx[0],gidx[1]]))\n",
    "                if ((gmax > max_intensity)):\n",
    "                        gn.append(n)\n",
    "                        continue\n",
    "                else:\n",
    "                        label_grid2d[label_grid2d==n]==0\n",
    "\n",
    "        #Reset label count (starting from 0)\n",
    "        gn = np.int32(gn)\n",
    "        for i,g in enumerate(gn):\n",
    "                label_grid2d[label_grid2d==g] == i\n",
    "\n",
    "        #Filter labels by size (mininum size for perturbation region is 25 gridboxes: i.e. (5km x 5km) * 25 = 625 km^2)\n",
    "        label_grid2d = labeler1.size_filter(label_grid2d, min_area)\n",
    "        return label_grid2d\n",
    "    \n",
    "#Define function to retrieve perturbation objects from labeled analysis\n",
    "def extract_objects(data,label_grid,x_grid,y_grid):\n",
    "        dx=1\n",
    "        dt=1\n",
    "        #Initialize array corresponding to the number of times/frames in the dataset\n",
    "        times = np.arange(0,label_grid.shape[0])\n",
    "\n",
    "        #Initialize arrays\n",
    "        coms_x = []; coms_y = []; coms_x2 = []; coms_y2 = []; frames = []; coms_xlat = []; coms_xlng = []\n",
    "        cg_x = []; cg_y = []\n",
    "        storm_objects = []\n",
    "        \n",
    "        #Retrieve indices of the grid\n",
    "        ij_grid = np.indices(label_grid.shape[1:])\n",
    "\n",
    "        #For each time\n",
    "        for t, tim in enumerate(times):\n",
    "            \n",
    "                #Compute the center of mass of objects at time (t)\n",
    "                com = list(center_of_mass(data[t], labels=label_grid[t], index=np.arange(1, label_grid[t].max() + 1)))\n",
    "                com = [c for c in com if (np.isnan(c[0])!=1)]\n",
    "\n",
    "                cmxx = []; cmyy = []\n",
    "                if (len(com)>0):\n",
    "                        #Combine all data into single array for trackpy\n",
    "                        for cm in com:\n",
    "\n",
    "                                cxi = int(cm[1]) #longitude_idx\n",
    "                                cyi = int(cm[0]) #latitude_idx\n",
    "\n",
    "                                cxd = cm[1]-cxi #longtiude shift\n",
    "                                cyd = cm[0]-cyi #latitude shift\n",
    "\n",
    "                                #Grid spacing in zonal and meridional direction (in km)\n",
    "                                cxx = (funcs.haversine(Y[cyi,cxi],X[cyi,cxi],Y[cyi,cxi+1],X[cyi,cxi+1]))\n",
    "                                cyy = (funcs.haversine(Y[cyi,cxi],X[cyi,cxi],Y[cyi+1,cxi],X[cyi+1,cxi]))\n",
    "\n",
    "                                #x,y components of shift (in kms)\n",
    "                                cxx = cxx*cxd\n",
    "                                cyy = cyy*cyd\n",
    "\n",
    "                                #Distance from lower right corner gridpoint\n",
    "                                hypot = (cxx**2.0 + cyy**2.0)**0.5\n",
    "                                #Angle of distance vector\n",
    "                                theta = np.arctan2(cyy,cxx)\n",
    "\n",
    "                                #Compute longitude,latitude position of center of mass (from subpixels)\n",
    "                                cxn,cyn = funcs.get_pos(theta,hypot,X[cyi,cxi],Y[cyi,cxi])\n",
    "\n",
    "                                #Save center of mass to add to STObject\n",
    "                                cmxx.append(cxn)\n",
    "                                cmyy.append(cyn)\n",
    "\n",
    "                                #Store subpixel float index of center of mass\n",
    "                                coms_x2.append(cm[0])\n",
    "                                coms_y2.append(cm[1])\n",
    "\n",
    "                                #Store center of mass (longitude,latitude) position\n",
    "                                coms_xlng.append(cxn)\n",
    "                                coms_xlat.append(cyn)\n",
    "                                \n",
    "                                #Store frame\n",
    "                                frames.append(t)\n",
    "\n",
    "                        #Find objects in the labeled data at time (t)\n",
    "                        object_slices = list(find_objects(label_grid[t], label_grid[t].max()))\n",
    "\n",
    "                        #If objects have been identified store each object in an STObject provided by the Hagelslag package.\n",
    "                        if len(object_slices) > 0:\n",
    "\n",
    "                                #Loop through each object\n",
    "                                for o, obj_slice in enumerate(object_slices):\n",
    "                                        #Add feature data to STObject\n",
    "                                        st=STObject(data[t][obj_slice],\n",
    "                                                np.where(label_grid[t][obj_slice] == o + 1, 1, 0),\n",
    "                                                x_grid[obj_slice],\n",
    "                                                y_grid[obj_slice],\n",
    "                                                ij_grid[0][obj_slice],\n",
    "                                                ij_grid[1][obj_slice],\n",
    "                                                tim,\n",
    "                                                tim,\n",
    "                                                dx=dx,\n",
    "                                                step=dt)\n",
    "\n",
    "                                        #Define center of mass of found object\n",
    "                                        st.center_of_mass = cmxx[o],cmyy[o]\n",
    "                                        storm_objects.append(st)\n",
    "\n",
    "        #Convert lists to numpy arrays\n",
    "        coms_x2 = np.float32(coms_x2)\n",
    "        coms_y2 = np.float32(coms_y2)\n",
    "        coms_xlat = np.float32(coms_xlat)\n",
    "        coms_xlng = np.float32(coms_xlng)\n",
    "        frames = np.int32(frames)\n",
    "\n",
    "        #Return feature data frame and list of objects\n",
    "        df = pd.DataFrame(dict(x=coms_x2,y=coms_y2,frame=frames,lat=coms_xlat,lng=coms_xlng))\n",
    "        return df,storm_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_maxarea = 2500 #Set area theshold (perturbation must exceed this area at some point during its lifetime)\n",
    "\n",
    "def write_traj(sign,meso,X,Y,ds):\n",
    "    #Flip sign of perturbations to facillitate labelling (if negative)\n",
    "    if (sign == 'positive'):\n",
    "            meso_pos = meso\n",
    "    else:\n",
    "            meso_neg = meso*-1\n",
    "\n",
    "    #label perturbations on grid\n",
    "    num_cores = 8\n",
    "    if (sign == 'positive'):\n",
    "            label_grid = Parallel(n_jobs=num_cores)(delayed(label_2d)(d,data2d) for d,data2d in enumerate(meso_pos))\n",
    "    else:\n",
    "            label_grid = Parallel(n_jobs=num_cores)(delayed(label_2d)(d,data2d) for d,data2d in enumerate(meso_neg))\n",
    "\n",
    "    #Save labels to netcdf\n",
    "    label_grid = np.array(label_grid,dtype=np.int8)\n",
    "    label_xarr = xr.DataArray(label_grid,coords=ds[otyp+'_meso'].coords,dims=ds[otyp+'_meso'].dims)\n",
    "\n",
    "    #Write labeled grid to netcdf\n",
    "    dl = xr.Dataset()\n",
    "    dl['label_'+sign] = label_xarr\n",
    "    dl.to_netcdf('../../data/Tracks/label_grid_meso_'+sign+'_'+otyp+'_'+day2+'.nc')\n",
    "    dl.close()\n",
    "    \n",
    "    if (sign == 'positive'):\n",
    "            #Identify features and extract objects\n",
    "            df,stos = extract_objects(meso_pos,label_grid,X,Y)\n",
    "    else:\n",
    "            #Make negative perturbations positive since min/max intensity is > 0\n",
    "            df,stos = extract_objects(meso_neg,label_grid,X,Y)\n",
    "\n",
    "    stos = np.array(stos)\n",
    "\n",
    "    #Save center of mass coordinates for all STObjects\n",
    "    cms = [s.center_of_mass for s in stos]\n",
    "    cmx = np.array([c[0] for c in cms])\n",
    "    cmy = np.array([c[1] for c in cms])\n",
    "    \n",
    "    tmax = 12; #Minimum duration (in 5-min periods)\n",
    "\n",
    "    #Perform particle tracking (allow lapse of 2 frames and links up to 5 points away)\n",
    "    t = tp.link_df(df, 5, memory=2)\n",
    "    t1 = tp.filter_stubs(t, tmax) #Set minum duration of tracjectory (i.e. 12*5min = 1 hour)\n",
    "\n",
    "    #Group trajectories\n",
    "    grouped = t.groupby('particle')\n",
    "    t1 = grouped.filter(lambda x: x.frame.count() >= tmax,dropna=True)\n",
    "\n",
    "    #Print track counts\n",
    "    print('Before:', t['particle'].nunique())\n",
    "    print('After:', t1['particle'].nunique())\n",
    "    \n",
    "    #Identify unique trajectories\n",
    "    parts = t1['particle'].unique()\n",
    "    \n",
    "    #Search for spurious discontinuity between trajectories\n",
    "    #Consider two trajectories whose starting & endpoints are very close. In this scenario the trajectories should be combined into a single trajectory.\n",
    "    traj_st = []; traj_et = []; stg = []; gparts = []; ext = []\n",
    "    stg = [None]*len(t1) #initialize storm object array\n",
    "    \n",
    "    #Loop through each trajectory\n",
    "    for j,p in enumerate(parts):\n",
    "        \n",
    "            #Subset dataframe by particle (trajectory)\n",
    "            t11 = t1[(t1['particle'].values==p)]\n",
    "            gidx = np.argwhere(t1['particle'].values==p).T[0]\n",
    "\n",
    "            #Get the coordinates of the particle\n",
    "            x1,y1 = np.int32(t11['x'].values),np.int32(t11['y'].values)\n",
    "            lngs,lats = t11['lng'].values,t11['lat'].values\n",
    "            \n",
    "            #Get list of frames in which particle appears\n",
    "            ts = np.int32(t11['frame'].values)\n",
    "\n",
    "            mss = []; didxs = []\n",
    "            for i in range(0,len(x1)):\n",
    "                    #Retrieve objects identified during each frame the particle is observed\n",
    "                    stot = stos[t['frame'].values==ts[i]]\n",
    "                    cmx_0 = cmx[t['frame'].values==ts[i]]\n",
    "                    cmy_0 = cmy[t['frame'].values==ts[i]]\n",
    "\n",
    "                    #Match the object to the particle by comparing the center of mass of the object and the location of the particle in each frame\n",
    "                    dist = funcs.haversine(lngs[i],lats[i],cmx_0,cmy_0)\n",
    "                    didx = np.argmin(dist)\n",
    "                    so = stot[didx]\n",
    "\n",
    "                    didxs.append(didx)\n",
    "                    mss.append(so.max_size())\n",
    "\n",
    "            mss = 25.0*np.array(mss); #Convert storm object (max_size()) from pixel count to km^2\n",
    "\n",
    "            #Ensure that the track perturbation meets the maximum area threshold (2500 km^2). \n",
    "            #Below, filter out perturbations whose maximum area never exceeds 2500 km^2.\n",
    "            if (max(mss) >= min_maxarea): \n",
    "                    for k in range(0,len(x1)):\n",
    "                            #Retrieve objects identified during each frame the particle is observed\n",
    "                            stot = stos[t['frame'].values==ts[k]]\n",
    "                            so = stot[didxs[k]]\n",
    "                            stg[gidx[k]] = so\n",
    "\n",
    "                    #Store the starting and ending position and frame of the tracked particle (center of mass)\n",
    "                    traj_st.append([x1[0],y1[0],ts[0]]) \n",
    "                    traj_et.append([x1[-1],y1[-1],ts[-1]])\n",
    "                    gparts.append(t11)\n",
    "                    ext.append(25*max(mss)) #Define maximum area of perturbation\n",
    "    \n",
    "    #tnc = pd.concat(gparts)\n",
    "    stg = np.asarray(stg)\n",
    "    ext = np.array(ext)\n",
    "\n",
    "    #Filter tracks\n",
    "    t1 = t1.iloc[np.where(stg!=None)]\n",
    "    stg = stg[np.where(stg!=None)]\n",
    "\n",
    "    #Smooth trajectories with Kalman Filter\n",
    "    print('After Area: ', t1['particle'].nunique())\n",
    "    tnew,stg_new = smooth_trajs(t1,stg)\n",
    "    t1x = tnew.to_xarray()\n",
    "    \n",
    "    #Save tracks to file\n",
    "    print('Final: ', tnew['particle'].nunique())\n",
    "    t1x.to_netcdf('../../data/Tracks/particle_trajectories_meso_'+sign+'_'+otyp+'_'+day2+'.nc')\n",
    "    np.save('../../data/Tracks/storm_objects_meso_'+sign+'_'+otyp+'_'+day2+'.npy',stg_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 564: 1 trajectories present.\n",
      "Before: 50\n",
      "After: 14\n",
      "After Area:  14\n",
      "Final:  14\n"
     ]
    }
   ],
   "source": [
    "#Track positive perturbations\n",
    "write_traj('positive',vvar_meso,X,Y,dsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 549: 1 trajectories present.\n",
      "Before: 36\n",
      "After: 14\n",
      "After Area:  13\n",
      "Final:  13\n"
     ]
    }
   ],
   "source": [
    "#Track negative perturbations\n",
    "write_traj('negative',vvar_meso,X,Y,dsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size': 24})\n",
    "\n",
    "#Plot perturbation trajectories\n",
    "def plot_track(sign,t1,tt,ddate):\n",
    "        #Start at 1200 UTC 14, May\n",
    "        tt = tt+144\n",
    "        #Retrieve 5-min reflectivity and altimeter analysis\n",
    "        rfl_2d = refl[tt]\n",
    "        #Mask altimeter analysis over water\n",
    "        vvar_meso_2d = mask_grid(vvar_meso[tt])\n",
    "        #Smooth altimeter analysis for contouring\n",
    "        vvar_meso_2d_smooth = ndimage.gaussian_filter(vvar_meso_2d,sigma=2.5)\n",
    "\n",
    "        #Initialize Figure\n",
    "        fig =plt.figure(figsize=(26,8))\n",
    "\n",
    "        #Plot mesoscale (bandpass) pressure perturbation analysis\n",
    "        ax1 = plt.subplot(121,projection=crs.PlateCarree())\n",
    "        add_map(ax1,'dimgray',1) #Add States/borders\n",
    "        add_gridlines(ax1,True,True,'k',18) #Add grid lines and x/y labels  \n",
    "        im = ax1.imshow(vvar_meso_2d,origin='lower',extent=[minLng,maxLng,minLat,maxLat],cmap=cmr.fusion_r,vmin=-2,vmax=2)\n",
    "        \n",
    "        #Contour positive and negative perturbations at 0.75 and -0.75 hPa, respectively \n",
    "        CS = ax1.contour(X,Y,vvar_meso_2d,levels=[0.75],colors='k',alpha=1)\n",
    "        CS = ax1.contour(X,Y,vvar_meso_2d,levels=[-0.75],ls='--',colors='k',alpha=1)\n",
    "        ax1.clabel(CS, CS.levels, inline=True, fmt=\"%1.2f\", fontsize=14, colors='k') #add contour labels\n",
    "        \n",
    "        #Set grid bounds\n",
    "        ax1.set_xlim([minLng,maxLng])\n",
    "        ax1.set_ylim([minLat,maxLat])\n",
    "        ax1.set_title('Mesoscale (2-6 h) Band-pass Altimeter w. Tracks',fontsize=22)\n",
    "        cb=plt.colorbar(im,fraction=0.023) #Shrink colorbar to fit plot height\n",
    "        cb.ax.set_title('($hPa$)',y=1.02,fontsize=18) #Set colorbar title\n",
    "        cb.ax.tick_params(labelsize=18) #Set colorbar tick size   \n",
    "\n",
    "        #Retrieve particle trajectories\n",
    "        all_parts = t1['particle'].values\n",
    "        tdiff = abs(t1['frame'].values-tt) #Adjust frame for starting time (tt)\n",
    "\n",
    "        #Find tracks present within nearest five frames.\n",
    "        tidx = np.argwhere(tdiff<=5).T[0] \n",
    "\n",
    "        #Extract tracks during current and adjacent frames\n",
    "        pparts = [all_parts[t] for t in tidx]\n",
    "        #Get unique indices for tracks\n",
    "        pparts = np.unique(pparts)\n",
    "        #Loop through each trajectory\n",
    "        for i,p in enumerate(pparts):\n",
    "                #Get trajectory p\n",
    "                t11 = t1[(t1['particle']==p)]\n",
    "                #Retrieve frames from track\n",
    "                ts = t11['frame'].values\n",
    "                #Get position data for track\n",
    "                xarr,yarr = np.float32(t11['lng'].values),np.float32(t11['lat'].values)\n",
    "\n",
    "                #If the starting time is after the current frame or the ending time is before the current frame do not plot the track\n",
    "                if ((ts[0] > tt) or (ts[-1] < tt)): #or (sumdist <= 50)):\n",
    "                        continue\n",
    "\n",
    "                #Plot the perturbation track from start to the present time (frame)\n",
    "                tdiff = abs(ts-tt)\n",
    "                midx = np.argmin(tdiff)\n",
    "                xarr = xarr[:midx+1]; yarr = yarr[:midx+1]\n",
    "                ax1.plot(xarr,yarr,'-k',ms=10,lw=1.5)\n",
    "                ax1.scatter(xarr[-1],yarr[-1],color='k',s=25)\n",
    "\n",
    "        #Plot composite reflectivity analysis\n",
    "        ax2 = plt.subplot(122,projection=crs.PlateCarree())\n",
    "        add_map(ax2,'dimgray',1) #Add States/borders\n",
    "        add_gridlines(ax2,True,True,'k',18) #Add grid lines and x/y labels  \n",
    "        im = ax2.imshow(rfl_2d,origin='lower',extent=[minLng,maxLng,minLat,maxLat],cmap=cmapp_radar,vmin=-32,vmax=90,zorder=2,alpha=0.8)\n",
    "        \n",
    "        #Set grid bounds\n",
    "        ax2.set_xlim([minLng,maxLng])\n",
    "        ax2.set_ylim([minLat,maxLat])\n",
    "        ax2.set_title('Composite Reflectivity',fontsize=22)\n",
    "        cb=plt.colorbar(im,fraction=0.023) #Shrink colorbar to fit plot height\n",
    "        cb.ax.set_title('($dBZ$)',y=1.02,fontsize=18) #Set colorbar title\n",
    "        cb.ax.tick_params(labelsize=18) #Set colorbar tick size\n",
    "                \n",
    "        #Save image with %03d format for animation with ffmpeg\n",
    "        tt = tt-144\n",
    "        if (tt < 10):\n",
    "            dd = '00'+str(tt)\n",
    "        elif ((tt >= 10) and (tt < 100)):\n",
    "            dd = '0'+str(tt)\n",
    "        else:\n",
    "            dd = str(tt)\n",
    "\n",
    "        plt.suptitle('5-min Analysis '+ddate[9:13]+' UTC '+ddate[6:8]+'/'+ddate[4:6]+'/'+ddate[0:4],fontsize=24)\n",
    "        fig.canvas.draw()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../../Plots/'+day2+'/ppert_meso_'+sign+'_'+otyp+'_'+dd+'.png')\n",
    "        plt.clf()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve trajectories for positive perturbations\n",
    "sign='positive'\n",
    "t1x = xr.open_dataset('../../data/Tracks/particle_trajectories_meso_'+sign+'_'+otyp+'_'+day2+'.nc')\n",
    "t2 = t1x.to_dataframe()\n",
    "#Perform plotting in parallel (one plot - per core)\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "results = Parallel(n_jobs=num_cores)(delayed(plot_track)(sign,t2,d,ddate) for d,ddate in enumerate(dtlist[144:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If animation (mp4 movie) already exists, remove it so ffmpeg won't ask to overwrite\n",
    "if os.path.isfile('../../Plots/'+day2+'/ppert_meso_'+sign+'_'+otyp+'_'+day2+'.mp4'):\n",
    "    os.system('rm -rf ../../Plots/'+day2+'/ppert_meso_'+sign+'_'+otyp+'_'+day2+'.mp4')\n",
    "#Create mp4 movie from 5-min pressure perturbation / reflectivity anlayses saved as pngs\n",
    "os.system('ffmpeg -r 12 -f image2 -s 1920x1080 -i ../../Plots/'+day2+'/ppert_meso_'+sign+'_'+otyp+'_%03d.png -c:v libx264 -pix_fmt yuv420p ../../Plots/'+day2+'/ppert_meso_'+sign+'_'+otyp+'_'+day2+'.mp4')\n",
    "#(Below) display video of positive perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div align=\"middle\">\n",
       "<video width=\"100%\" controls>\n",
       "      <source src = \"../../Plots/20180515/ppert_meso_positive_altimeter_20180515.mp4\" type=\"video/mp4\">\n",
       "</video></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<div align=\"middle\">\n",
    "<video width=\"100%\" controls>\n",
    "      <source src = \"../../Plots/20180515/ppert_meso_positive_altimeter_20180515.mp4\" type=\"video/mp4\">\n",
    "</video></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve trajectories for negative perturbations\n",
    "sign='negative'\n",
    "t1x = xr.open_dataset('../../data/Tracks/particle_trajectories_meso_'+sign+'_'+otyp+'_'+day2+'.nc')\n",
    "t2 = t1x.to_dataframe()\n",
    "#Perform plotting in parallel (one plot - per core)\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "results = Parallel(n_jobs=num_cores)(delayed(plot_track)(sign,t2,d,ddate) for d,ddate in enumerate(dtlist[144:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If animation (mp4 movie) already exists, remove it so ffmpeg won't ask to overwrite\n",
    "if os.path.isfile('../../Plots/'+day2+'/ppert_meso_'+sign+'_'+otyp+'_'+day2+'.mp4'):\n",
    "    os.system('rm -rf ../../Plots/'+day2+'/ppert_meso_'+sign+'_'+otyp+'_'+day2+'.mp4')\n",
    "#Create mp4 movie from 5-min pressure perturbation / reflectivity anlayses saved as pngs\n",
    "os.system('ffmpeg -r 12 -f image2 -s 1920x1080 -i ../../Plots/'+day2+'/ppert_meso_'+sign+'_'+otyp+'_%03d.png -c:v libx264 -pix_fmt yuv420p ../../Plots/'+day2+'/ppert_meso_'+sign+'_'+otyp+'_'+day2+'.mp4')\n",
    "#(Below) display video of negative tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div align=\"middle\">\n",
       "<video width=\"100%\" controls>\n",
       "      <source src = \"../../Plots/20180515/ppert_meso_negative_altimeter_20180515.mp4\" type=\"video/mp4\">\n",
       "</video></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<div align=\"middle\">\n",
    "<video width=\"100%\" controls>\n",
    "      <source src = \"../../Plots/20180515/ppert_meso_negative_altimeter_20180515.mp4\" type=\"video/mp4\">\n",
    "</video></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
